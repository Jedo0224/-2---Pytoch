{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "expected-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xor- 하나의 레이어드를 갖는 perceptron으로는 실행될 수 없다.\n",
    "# 여러개의 층을 갖는 Mulitilayer Perception을 사용한다.\n",
    "\n",
    "# Backpropagation - Loss에 대해서 / 이전값을 이용하여 최소값을 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "smoking-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# for reproducibility\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sonic-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
    "learning_rate = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adjusted-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "\n",
    "w1 = torch.Tensor(2,2).to(device)\n",
    "b1 = torch.Tensor(2).to(device)\n",
    "w2 = torch.Tensor(2,1).to(device)\n",
    "b2 = torch.Tensor(1).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "unusual-lottery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3173])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.init.normal_(w1)  #정규분포에서 가져온 값으로 텐서를 채운다.\n",
    "torch.nn.init.normal_(b1)\n",
    "torch.nn.init.normal_(w2)\n",
    "torch.nn.init.normal_(b2)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "interior-silly",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "close-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_prime(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "involved-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9433, -0.6758],\n",
       "        [ 0.7452, -0.1203],\n",
       "        [-1.3448, -1.2691],\n",
       "        [ 0.3437, -0.7137]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = torch.add(torch.matmul(X,w1),b1)\n",
    "a1 = sigmoid(l1)\n",
    "l2 = torch.add(torch.matmul(a1,w2),b2)\n",
    "Y_pred = sigmoid(l2)\n",
    "\n",
    "l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "banned-fellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8633197546005249\n",
      "100 0.17553460597991943\n",
      "200 0.030606765300035477\n",
      "300 0.015832239761948586\n",
      "400 0.010592210106551647\n",
      "500 0.00793561339378357\n",
      "600 0.00633580144494772\n",
      "700 0.005268664564937353\n",
      "800 0.004506990313529968\n",
      "900 0.003936456050723791\n",
      "1000 0.003493288066238165\n",
      "1100 0.003139264415949583\n",
      "1200 0.0028499953914433718\n",
      "1300 0.0026093448977917433\n",
      "1400 0.0024059051647782326\n",
      "1500 0.0022317536640912294\n",
      "1600 0.002080997684970498\n",
      "1700 0.0019492306746542454\n",
      "1800 0.0018330368911847472\n",
      "1900 0.0017299295868724585\n",
      "2000 0.0016377231804654002\n",
      "2100 0.0015548007795587182\n",
      "2200 0.001479830825701356\n",
      "2300 0.0014117503305897117\n",
      "2400 0.0013496027095243335\n",
      "2500 0.0012927292846143246\n",
      "2600 0.0012404125882312655\n",
      "2700 0.0011921292170882225\n",
      "2800 0.001147460425272584\n",
      "2900 0.0011060029501095414\n",
      "3000 0.0010674424702301621\n",
      "3100 0.0010314506944268942\n",
      "3200 0.000997832976281643\n",
      "3300 0.0009662907687015831\n",
      "3400 0.0009367043385282159\n",
      "3500 0.0009088496444746852\n",
      "3600 0.0008826220873743296\n",
      "3700 0.0008578277193009853\n",
      "3800 0.000834391568787396\n",
      "3900 0.0008122242288663983\n",
      "4000 0.0007911762804724276\n",
      "4100 0.0007712027872912586\n",
      "4200 0.0007522144005633891\n",
      "4300 0.0007341363234445453\n",
      "4400 0.0007168641313910484\n",
      "4500 0.0007004275103099644\n",
      "4600 0.0006846922915428877\n",
      "4700 0.0006697180797345936\n",
      "4800 0.0006553108687512577\n",
      "4900 0.0006415153620764613\n",
      "5000 0.0006282868562266231\n",
      "5100 0.0006156253512017429\n",
      "5200 0.0006034411489963531\n",
      "5300 0.0005917195230722427\n",
      "5400 0.0005804455140605569\n",
      "5500 0.0005696338484995067\n",
      "5600 0.0005591803346760571\n",
      "5700 0.0005490847979672253\n",
      "5800 0.0005393621977418661\n",
      "5900 0.0005299827316775918\n",
      "6000 0.0005209313821978867\n",
      "6100 0.000512178405188024\n",
      "6200 0.0005036938819102943\n",
      "6300 0.0004954928299412131\n",
      "6400 0.0004875602026004344\n",
      "6500 0.0004798811860382557\n",
      "6600 0.0004724407917819917\n",
      "6700 0.00046522411867044866\n",
      "6800 0.00045821626554243267\n",
      "6900 0.00045141723239794374\n",
      "7000 0.00044484189129434526\n",
      "7100 0.00043843057937920094\n",
      "7200 0.00043221324449405074\n",
      "7300 0.0004261599387973547\n",
      "7400 0.00042025576112791896\n",
      "7500 0.00041454541496932507\n",
      "7600 0.00040895442361943424\n",
      "7700 0.00040352746145799756\n",
      "7800 0.0003982943599112332\n",
      "7900 0.00039310602005571127\n",
      "8000 0.0003880966396536678\n",
      "8100 0.0003832214279100299\n",
      "8200 0.0003784506698139012\n",
      "8300 0.0003737991792149842\n",
      "8400 0.00036925211315974593\n",
      "8500 0.0003648242854978889\n",
      "8600 0.0003605008532758802\n",
      "8700 0.0003563116188161075\n",
      "8800 0.0003521522448863834\n",
      "8900 0.00034811210935004056\n",
      "9000 0.0003441764274612069\n",
      "9100 0.00034033015253953636\n",
      "9200 0.0003365734010003507\n",
      "9300 0.0003328613529447466\n",
      "9400 0.0003292685723863542\n",
      "9500 0.0003257354546803981\n",
      "9600 0.0003222769300919026\n",
      "9700 0.0003188780101481825\n",
      "9800 0.0003155834274366498\n",
      "9900 0.000312378368107602\n",
      "10000 0.00030918820993974805\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    l1 = torch.add(torch.matmul(X,w1),b1)\n",
    "    a1 = sigmoid(l1)\n",
    "    l2 = torch.add(torch.matmul(a1,w2),b2)\n",
    "    Y_pred = sigmoid(l2)\n",
    "    \n",
    "    cost = -torch.mean(Y * torch.log(Y_pred) + (1-Y)*torch.log(1-Y_pred))\n",
    "    \n",
    "    \n",
    "    d_Y_pred = (Y_pred-Y)/(Y_pred*(1.0 - Y_pred) + 1e-7)\n",
    "    \n",
    "    d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
    "    d_b2 = d_l2\n",
    "    d_w2 = torch.matmul(torch.transpose(a1,0,1), d_b2)\n",
    "    \n",
    "    d_a1 = torch.matmul(d_b2,torch.transpose(w2,0,1))\n",
    "    d_l1 = d_a1*sigmoid_prime(l1)\n",
    "    d_b1 = d_l1\n",
    "    d_w1 = torch.matmul(torch.transpose(X,0,1),d_b1)\n",
    "    \n",
    "    w1 = w1 - learning_rate*d_w1\n",
    "    b1 = b1 - learning_rate*torch.mean(d_b1,0)\n",
    "    w2 = w2 - learning_rate*d_w2\n",
    "    b2 = b2 - learning_rate*torch.mean(d_b2,0)\n",
    "    \n",
    "    if step % 100 == 0:\n",
    "        print(step,cost.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-torture",
   "metadata": {},
   "source": [
    "# code : xor-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "grateful-colonial",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
    "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "reflected-tackle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.698296844959259\n",
      "100 0.6934823393821716\n",
      "200 0.693169116973877\n",
      "300 0.6929329633712769\n",
      "400 0.6923756003379822\n",
      "500 0.6897302865982056\n",
      "600 0.6722687482833862\n",
      "700 0.5978021025657654\n",
      "800 0.5267641544342041\n",
      "900 0.45419931411743164\n",
      "1000 0.19452804327011108\n",
      "1100 0.07690239697694778\n",
      "1200 0.044948603957891464\n",
      "1300 0.03134451434016228\n",
      "1400 0.02393999695777893\n",
      "1500 0.019313938915729523\n",
      "1600 0.016160117462277412\n",
      "1700 0.013876940123736858\n",
      "1800 0.01215001754462719\n",
      "1900 0.010799450799822807\n",
      "2000 0.009715132415294647\n",
      "2100 0.008825806900858879\n",
      "2200 0.008083634078502655\n",
      "2300 0.007455028127878904\n",
      "2400 0.006915979087352753\n",
      "2500 0.006448732223361731\n",
      "2600 0.006039889063686132\n",
      "2700 0.005679231137037277\n",
      "2800 0.005358721129596233\n",
      "2900 0.005072119180113077\n",
      "3000 0.004814260173588991\n",
      "3100 0.004581078886985779\n",
      "3200 0.00436922162771225\n",
      "3300 0.004175920505076647\n",
      "3400 0.003998815547674894\n",
      "3500 0.0038359984755516052\n",
      "3600 0.00368577241897583\n",
      "3700 0.0035467848647385836\n",
      "3800 0.0034178057685494423\n",
      "3900 0.0032977990340441465\n",
      "4000 0.0031858498696237803\n",
      "4100 0.003081193193793297\n",
      "4200 0.0029830792918801308\n",
      "4300 0.002891072304919362\n",
      "4400 0.002804454183205962\n",
      "4500 0.00272283423691988\n",
      "4600 0.0026458229403942823\n",
      "4700 0.0025730158668011427\n",
      "4800 0.0025040386244654655\n",
      "4900 0.0024386814329773188\n",
      "5000 0.0023765997029840946\n",
      "5100 0.002317568752914667\n",
      "5200 0.002261409303173423\n",
      "5300 0.002207836601883173\n",
      "5400 0.0021567759104073048\n",
      "5500 0.002108017448335886\n",
      "5600 0.002061336999759078\n",
      "5700 0.0020166896283626556\n",
      "5800 0.0019739256240427494\n",
      "5900 0.0019329250790178776\n",
      "6000 0.0018935836851596832\n",
      "6100 0.0018557964358478785\n",
      "6200 0.0018194885924458504\n",
      "6300 0.0017845556139945984\n",
      "6400 0.0017509970348328352\n",
      "6500 0.0017185742035508156\n",
      "6600 0.0016873616259545088\n",
      "6700 0.0016572396270930767\n",
      "6800 0.0016281632706522942\n",
      "6900 0.0016000878531485796\n",
      "7000 0.0015729833394289017\n",
      "7100 0.0015467898920178413\n",
      "7200 0.0015214182203635573\n",
      "7300 0.0014968379400670528\n",
      "7400 0.001473064417950809\n",
      "7500 0.0014500075485557318\n",
      "7600 0.0014276824658736587\n",
      "7700 0.0014059997629374266\n",
      "7800 0.0013849888928234577\n",
      "7900 0.0013645902508869767\n",
      "8000 0.0013448038371279836\n",
      "8100 0.0013255252270027995\n",
      "8200 0.001306813908740878\n",
      "8300 0.0012886550975963473\n",
      "8400 0.001270929235033691\n",
      "8500 0.0012537409784272313\n",
      "8600 0.001236925832927227\n",
      "8700 0.00122061837464571\n",
      "8800 0.0012047139462083578\n",
      "8900 0.00118924246635288\n",
      "9000 0.0011741293128579855\n",
      "9100 0.0011594340903684497\n",
      "9200 0.0011450524907559156\n",
      "9300 0.001131043885834515\n",
      "9400 0.0011173636885359883\n",
      "9500 0.001104026916436851\n",
      "9600 0.0010909887496381998\n",
      "9700 0.0010782638564705849\n",
      "9800 0.0010658225510269403\n",
      "9900 0.0010536499321460724\n",
      "10000 0.001041745999827981\n"
     ]
    }
   ],
   "source": [
    "linear1 = torch.nn.Linear(2,2,bias = True) # MLP what is torch.nn.Linear?\n",
    "linear2 = torch.nn.Linear(2,1,bias = True) \n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid,linear2,sigmoid).to(device) # what is Sequential?\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device) # what is criterion?\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step,cost.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-initial",
   "metadata": {},
   "source": [
    "# Code : xor-nn-wide-deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acceptable-mapping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7129201889038086\n",
      "100 0.693131685256958\n",
      "200 0.6931272745132446\n",
      "300 0.6931226253509521\n",
      "400 0.6931177377700806\n",
      "500 0.6931125521659851\n",
      "600 0.693107008934021\n",
      "700 0.6931009292602539\n",
      "800 0.6930943727493286\n",
      "900 0.693087100982666\n",
      "1000 0.6930789947509766\n",
      "1100 0.6930698752403259\n",
      "1200 0.6930593848228455\n",
      "1300 0.6930474042892456\n",
      "1400 0.6930332779884338\n",
      "1500 0.6930167078971863\n",
      "1600 0.6929969787597656\n",
      "1700 0.6929730176925659\n",
      "1800 0.6929435729980469\n",
      "1900 0.6929067373275757\n",
      "2000 0.6928596496582031\n",
      "2100 0.6927981376647949\n",
      "2200 0.6927152276039124\n",
      "2300 0.6925999522209167\n",
      "2400 0.6924326419830322\n",
      "2500 0.6921772360801697\n",
      "2600 0.6917598247528076\n",
      "2700 0.691012442111969\n",
      "2800 0.6894866824150085\n",
      "2900 0.6856554746627808\n",
      "3000 0.6718228459358215\n",
      "3100 0.6037256121635437\n",
      "3200 0.5126228332519531\n",
      "3300 0.3379809260368347\n",
      "3400 0.015196681022644043\n",
      "3500 0.006400714628398418\n",
      "3600 0.0038961144164204597\n",
      "3700 0.002752020489424467\n",
      "3800 0.00210721418261528\n",
      "3900 0.0016971429577097297\n",
      "4000 0.0014150612987577915\n",
      "4100 0.0012099597370252013\n",
      "4200 0.0010545330587774515\n",
      "4300 0.0009329607128165662\n",
      "4400 0.0008354157325811684\n",
      "4500 0.000755567685700953\n",
      "4600 0.0006890128715895116\n",
      "4700 0.0006327961455099285\n",
      "4800 0.0005847088759765029\n",
      "4900 0.0005431098397821188\n",
      "5000 0.0005068053142167628\n",
      "5100 0.0004748256760649383\n",
      "5200 0.00044652947690337896\n",
      "5300 0.0004212603671476245\n",
      "5400 0.00039861572440713644\n",
      "5500 0.00037813305971212685\n",
      "5600 0.00035960369859822094\n",
      "5700 0.00034272929769940674\n",
      "5800 0.00032730112434364855\n",
      "5900 0.00031312531791627407\n",
      "6000 0.0003001272852998227\n",
      "6100 0.00028808339266106486\n",
      "6200 0.0002769339771475643\n",
      "6300 0.0002666194050107151\n",
      "6400 0.0002569756761658937\n",
      "6500 0.00024800279061309993\n",
      "6600 0.0002395665505900979\n",
      "6700 0.0002317265752935782\n",
      "6800 0.00022433380945585668\n",
      "6900 0.00021735846530646086\n",
      "7000 0.0002108302724082023\n",
      "7100 0.00020463000691961497\n",
      "7200 0.00019877261365763843\n",
      "7300 0.0001932729355758056\n",
      "7400 0.0001880117633845657\n",
      "7500 0.0001830486871767789\n",
      "7600 0.0001783092156983912\n",
      "7700 0.00017382313671987504\n",
      "7800 0.00016951592988334596\n",
      "7900 0.00016544718528166413\n",
      "8000 0.00016154241166077554\n",
      "8100 0.00015783138223923743\n",
      "8200 0.0001542694226372987\n",
      "8300 0.00015081178571563214\n",
      "8400 0.00014756282325834036\n",
      "8500 0.00014441819803323597\n",
      "8600 0.00014143750013317913\n",
      "8700 0.00013848664821125567\n",
      "8800 0.00013569972361437976\n",
      "8900 0.00013304693857207894\n",
      "9000 0.00013045377272646874\n",
      "9100 0.00012795002839993685\n",
      "9200 0.00012559533934108913\n",
      "9300 0.0001232704526046291\n",
      "9400 0.00012104988854844123\n",
      "9500 0.00011890384485013783\n",
      "9600 0.00011683232878567651\n",
      "9700 0.00011477571388240904\n",
      "9800 0.00011282342893537134\n",
      "9900 0.00011096056550741196\n",
      "10000 0.00010912750440184027\n"
     ]
    }
   ],
   "source": [
    "linear1 = torch.nn.Linear(2,10,bias = True) # MLP\n",
    "linear2 = torch.nn.Linear(10,10,bias = True)\n",
    "linear3 = torch.nn.Linear(10,10,bias = True)\n",
    "linear4 = torch.nn.Linear(10,1,bias = True)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "model = torch.nn.Sequential(linear1, sigmoid,linear2,sigmoid,linear3,sigmoid,linear4,sigmoid).to(device) # what is Sequential?\n",
    "\n",
    "criterion = torch.nn.BCELoss().to(device) # what is criterion?\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=1)\n",
    "\n",
    "for step in range(10001):\n",
    "    optimizer.zero_grad()\n",
    "    hypothesis = model(X)\n",
    "    cost = criterion(hypothesis,Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    if step % 100 == 0:\n",
    "        print(step,cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "other-action",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis:  [[6.6492255e-05]\n",
      " [9.9988770e-01]\n",
      " [9.9988079e-01]\n",
      " [1.3844538e-04]] \n",
      "Correct:  [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    hypothesis = model(X)\n",
    "    predicted = (hypothesis > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-divorce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
